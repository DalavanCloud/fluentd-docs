# Buffer Plugin Overview

Fluentd has 6 types of plugins: [Input](input-plugin-overview), [Parser](parser-plugin-overview), [Filter](filter-plugin-overview), [Output](output-plugin-overview), [Formatter](formatter-plugin-overview) and [Buffer](buffer-plugin-overview). This article gives an overview of Buffer Plugin.

We will first explain how Buffer Plugin works in general. Then, we will explain the mechanism of Time Sliced Plugin, a subclass of Buffer Plugin used by several core plugins.

## Buffer Plugin Overview

Buffer plugins are used in combination with the output plugins which support the buffering interface. For example, `out_file` uses file buffers by default for managing incoming data in chunks.

Buffer plugins are, as you can tell by the name, *pluggable*. So you can choose a suitable strategy for buffering records based on your system requirements.

## Buffer Structure

A buffer is essentially a queue of "chunks". A chunk is a collection of records concatenated into a single blob. Here is a diagram of how it works:

    :::text
    queue
    +---------+
    |         |
    |  chunk <-- write events to the top chunk
    |         |
    |  chunk  |
    |         |
    |  chunk  |
    |         |
    |  chunk --> write out the bottom chunk
    |         |
    +---------+

When the top chunk exceeds the specified size or time limit (`buffer_chunk_limit` and `flush_interval`, respectively), a new empty chunk is pushed to the top of the queue. The bottom chunk is written out immediately when new chunk is pushed.

If the bottom chunk fails to be written out, it will remain in the queue and Fluentd will retry after waiting several seconds (`retry_wait`). If the retry limit has not been disabled (`disable_retry_limit` is false) and the retry count exceeds the specified limit (`retry_limit`), the chunk is trashed. The retry wait time doubles each time (1.0sec, 2.0sec, 4.0sec, ...) until `max_retry_wait` is reached. If the queue length exceeds the specified limit (`buffer_queue_limit`), new events are rejected.

### Parameters

All buffered output plugins support the following parameters:

    :::text
    <match pattern>
      # omit the part about @type and other output parameters

      buffer_type memory
      buffer_chunk_limit 256m
      buffer_queue_limit 128
      flush_interval 60s
      disable_retry_limit false
      retry_limit 17
      retry_wait 1s
      max_retry_wait 10s # default is infinite
    </match>

`buffer_type` specifies the buffer plugin to use. The `memory` Buffer plugin is used by default. You can also specify `file` as the buffer type alongside the `buffer_path` parameter as follows:

    :::text
    <match pattern>
      # omit the part about @type and other output parameters

      buffer_type file
      buffer_path /var/fluentd/buffer/ #make sure fluentd has write access to the directory!
      ...
    </match>

The suffixes "s" (seconds), "m" (minutes), and "h" (hours) can be used for `flush_interval` and `retry_wait`. `retry_wait` can also be a decimal value.

The suffixes "k" (KB), "m" (MB), and "g" (GB) can be used for `buffer_chunk_limit`.

### Handling queue overflow

The `buffer_queue_full_action` option controls the behaviour when the queue becomes full. For now, three modes are supported:

 1. _exception_ (default)
    * This mode raises a `BufferQueueLimitError` exception to the input plugin.
    * This mode is suitable for data streaming.
    * It's up to input plugins to decide how to handle raised exceptions. For examples, `in_tail` stops reading new lines, `in_forward` returns an error to forward output.
 2. _block_
    * This mode stops input plugin thread until "buffer full" error is resolved.
    * This mode is good for batch-like use-case.
    * DO NOT use this option casually just for avoiding `BufferQueueLimitError` exceptions (see the below tips).
 3. _drop_oldest_chunk_
    * This mode drops the oldest chunks.
    * This mode is useful if the output destination is a monitoring system, since newer events are much more important than the older ones in this context.

#### Deployment tips

If your Fluentd daemon experiences overflows frequently, it basically means that your destination is insufficient for your traffic. There are several measures you can take:

 1. Tune the destination node to provide enough data-processing capacity.
 2. Use the `@ERROR` label to route overflowed events to another backup destination.
 3. Use the `<secondary>` tag to route overflowed events to another backup destination.

## Time Sliced Plugin Overview

Time Sliced Plugin is a type of Buffer Plugin, so, it has the same basic buffer structure as Buffer Plugin.

In addition, each chunk is keyed by time and flushed when that chunk's timestamp has passed. This is different from This immediately raises a couple of questions.

 1. How do we specify the granularity of time chunks? This is done through the `time_slice_format` option, which is set to "%Y%m%d" (daily) by default. If you want your chunks to be hourly, "%Y%m%d%H" will do the job.

 2. What if new logs come after the time corresponding the current chunk? For example, what happens to an event, timestamped at 2013-01-01 02:59:45 UTC, comes in at 2013-01-01 03:00:15 UTC? Would it make into the 2013-01-01 02:00:00-02:59:59 chunk?

  This issue is addressed by setting the `time_slice_wait` parameter. `time_slice_wait` sets, in seconds, how long fluentd waits to accept "late" events into the chunk *past the max time corresponding to that chunk*. The default value is 600, which means it waits for 10 minutes before moving on. So, in the current example, as long as the events come in before 2013-01-01 03:10:00, it will make it in to the 2013-01-01 02:00:00-02:59:59 chunk.

  Alternatively, you can also flush the chunks regularly using `flush_interval`. Note that `flush_interval` and `time_slice_wait` are mutually exclusive. If you set `flush_interval`, `time_slice_wait` will be ignored and fluentd would issue a warning.

Here is the diagram shows the relation between buffers and parameters.

<div>
  <a href="/images/buffer-internal-and-parameters.png">
    <img style='width: 100%;' src="/images/buffer-internal-and-parameters.png"/>
  </a>
</div>

## Secondary output

The backup destination that is used when retry count exceeds `retry_limit`. Currently, primary plugin type or `file` plugin works.

    ::text
    <match pattern>
      @type forward
      ...
      <secondary>
        @type file # or forward
        path /var/log/fluent/forward-failed
      </secondary>
    </match>

This is useful when primary destination or network condition is unstable.

##Notes

If you are curious which core output plugin use Buffered and which are Time Sliced, please see LINK:[the list here](/articles/output-plugin-overview#overview)

## List of Buffer Plugins

* [buf_memory](buf_memory)
* [buf_file](buf_file)
